{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3955901",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from datasets import Dataset\n",
    "\n",
    "def define_model(path_to_model):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(path_to_model)\n",
    "    model = AutoModelForCausalLM.from_pretrained(path_to_model,\n",
    "                                                 torch_dtype=\"auto\",\n",
    "                                                 device_map=\"auto\")\n",
    "    return tokenizer, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e28501",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Инициализация учителя\n",
    "\n",
    "teacher_tokenizer, teacher_model = define_model('./teacher_model/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6efc53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Инициализация few-shot'a\n",
    "\n",
    "few_shot = '''\n",
    "Problem:\n",
    "Olivia has $23. She bought five cupcakes for $3 each and a milkshake for $4. How much money does she have left?\n",
    "Solution:\n",
    "First, calculate the total cost of the cupcakes:\n",
    "5 cupcakes × $3 = $15.\n",
    "Add the cost of the milkshake: $15 + $4 = $19.\n",
    "Subtract from her initial amount: $23 − $19 = $4.\n",
    "So, Olivia has $4 left.\n",
    "Final Answer: 4​\n",
    "\n",
    "Problem:\n",
    "A bakery sells cookies in packs of 6. If a customer buys 9 packs, how many cookies does the customer get in total?\n",
    "Solution:\n",
    "Each pack contains 6 cookies.\n",
    "The customer buys 9 packs.\n",
    "Total cookies = 6 × 9 = 54.\n",
    "Final Answer: 54\n",
    "\n",
    "Problem:\n",
    "There are 42 students in a class. One-third of them are boys. How many girls are in the class?\n",
    "Solution:\n",
    "Number of boys = 42 ÷ 3 = 14.\n",
    "Number of girls = total students − boys = 42 − 14 = 28.\n",
    "Final Answer: 28\n",
    "\n",
    "Problem:\n",
    "A car travels 60 miles per hour. How many miles does it travel in 2 hours and 30 minutes?\n",
    "Solution:\n",
    "Convert 2 hours 30 minutes to hours: 2.5 hours.\n",
    "Distance = speed × time = 60 × 2.5 = 150 miles.\n",
    "Final Answer: 150\n",
    "\n",
    "Problem:\n",
    "James has 3 times as many marbles as Lisa. Together, they have 48 marbles. How many marbles does James have?\n",
    "\n",
    "Solution:\n",
    "Let Lisa have x marbles.\n",
    "Then James has 3x marbles.\n",
    "Together: x + 3x = 4x = 48.\n",
    "So, x = 48 ÷ 4 = 12.\n",
    "James has 3 × 12 = 36 marbles.\n",
    "Final Answer: 36\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4ea91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция генерации ответа на запрос\n",
    "\n",
    "def invoke_llm(type_of_model, task, few_shot=few_shot):\n",
    "\n",
    "    if type_of_model == 'teacher':\n",
    "        tokenizer = teacher_tokenizer\n",
    "        model = teacher_model\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "    messages = [{\"role\": \"user\", \n",
    "                 \"content\": few_shot + '\\n' + task}]\n",
    "    \n",
    "    text = tokenizer.apply_chat_template(messages,\n",
    "                                         tokenize=False,\n",
    "                                         add_generation_prompt=True,\n",
    "                                         enable_thinking=False)\n",
    "    \n",
    "    model_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "    generated_ids = model.generate(\n",
    "        **model_inputs,\n",
    "        max_new_tokens=32768\n",
    "    )\n",
    "\n",
    "    output_ids = generated_ids[0][len(model_inputs.input_ids[0]):].tolist()\n",
    "    content = tokenizer.decode(output_ids, skip_special_tokens=True).strip(\"\\n\")\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ddeb064",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импорт данных\n",
    "\n",
    "import polars as pl\n",
    "\n",
    "splits = {'train': 'main/train-00000-of-00001.parquet'}\n",
    "df_train = pl.read_parquet(\"hf://datasets/openai/gsm8k/\" + splits[\"train\"])\n",
    "\n",
    "questions = df_train['question'].to_list()\n",
    "answers = df_train['answer'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5419ec33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Генерация по таскам из GSM8K\n",
    "\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "with open(f'full_train_data_1.txt', 'a', encoding='utf-8', buffering=1) as f:\n",
    "    for q, a in tqdm(zip(questions, answers), total=len(questions)):\n",
    "        start_time = time.time()\n",
    "        teacher_response = invoke_llm('teacher', q)\n",
    "        f.write(teacher_response + '\\n')\n",
    "        f.write(f'-----'*20 + '\\n')\n",
    "        f.flush()\n",
    "        end_time = time.time()\n",
    "        elapsed_time = end_time - start_time"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
